{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1NMIUdPdXvIHDooiYFJuZQ6wub86v0E-u",
      "authorship_tag": "ABX9TyPFQwaPAfc+dRLwmnu2Aqoa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DungDuc/MEDNet/blob/main/MEDNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Readme\n",
        "In this notebook, you could:\n",
        "\n",
        "* Access the data and models from the following link:\n",
        "\n",
        "* Copy data and checkpoints files to your system, e.g. Google Drive.\n",
        "\n",
        "* Use the data and models for testing or re-experiment, e.g. mount the Google Drive and run the following cells on Google Colab.\n"
      ],
      "metadata": {
        "id": "hHSkQCHHVW5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "luJyCQQiVnyl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNuNq8K12wrw"
      },
      "outputs": [],
      "source": [
        "# import library\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, ZeroPadding2D, Concatenate, Multiply, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.layers import Conv1D, Conv2D, Conv2DTranspose, MaxPooling2D, AveragePooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D, Attention\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Activation, ReLU, Dense\n",
        "from tensorflow.keras.layers import Add, Multiply, Reshape, DepthwiseConv2D, UpSampling2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.metrics import *\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "import xml.etree.ElementTree as ET\n",
        "import struct\n",
        "import csv\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API"
      ],
      "metadata": {
        "id": "2HzpoTDHV0Db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class labels and colors\n",
        "AllTags = ['Reg1', 'Reg2', 'Reg3',\\\n",
        "        'Reg4', 'Reg5', 'Reg6',\\\n",
        "        'Reg7', 'Reg8', 'Reg9']\n",
        "\n",
        "#Colors = [[255,0,0], [0,255,0], [0,0,255],\\\n",
        "#Colors = [[0,255,0], [0,0,255], [255,0,0],\\\n",
        "Colors = [[0,0,255], [255,0,0], [0,255,0], \\\n",
        "          [255,255,0], [255,0,255], [0,255,255],\\\n",
        "          [128,0,0], [0,128,0], [0,0,128],\\\n",
        "          [255,255,255]]\n",
        "MaxColor = len(Colors)-1\n",
        "\n",
        "def set_label(Tags):\n",
        "    # class name and colors\n",
        "    nColor = len(Colors)\n",
        "    for i in range(len(Tags)):\n",
        "        class_names.append(Tags[i])\n",
        "        label_values.append(Colors[i%nColor])\n",
        "    # background\n",
        "    class_names.append('Background')\n",
        "    label_values.append([255,255,255])\n",
        "\n",
        "class_names, label_values = [],[]\n",
        "set_label(AllTags)\n",
        "\n",
        "# one-hot and colour coding\n",
        "def one_hot_it(code, num_classes):\n",
        "    masks = []\n",
        "    for i in range(num_classes):\n",
        "        mi = np.uint8((code==i))*1\n",
        "        masks.append(mi)\n",
        "    return np.stack(masks, axis=-1)\n",
        "\n",
        "def reverse_one_hot(image):\n",
        "    x = np.argmax(image, axis = -1).astype(np.uint16)\n",
        "    return x\n",
        "\n",
        "def colour_code_segmentation(img, MaxClass=0):\n",
        "    image = img.copy()\n",
        "    colour_codes = np.array(label_values).astype(np.uint8)\n",
        "    if MaxClass > 0:\n",
        "      image[image==MaxClass] = MaxColor\n",
        "    x = colour_codes[image.astype(np.uint16)]\n",
        "    return x\n",
        "\n",
        "\n",
        "class Region(object):\n",
        "    def __init__(self, tag = None, xmin=None, ymin=None, xmax=None, ymax=None, poly=None):\n",
        "        self.tag = tag\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        self.poly = poly\n",
        "    def iou(self, other):\n",
        "        if self.poly is not None and other.poly is not None:\n",
        "            return poly_iou(self.poly, other.poly)\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "def bb_iou(regA, regB):\n",
        "    # determine the (x, y)-coordinates of the intersection rectangle\n",
        "    xLeft = max(regA.xmin, regB.xmin)\n",
        "    yLeft = max(regA.ymin, regB.ymin)\n",
        "    xRight = min(regA.xmax, regB.xmax)\n",
        "    yRight = min(regA.ymax, regB.ymax)\n",
        "\n",
        "    if xLeft > xRight or yLeft > yRight:\n",
        "      return 0\n",
        "\n",
        "    # compute the area of intersection rectangle\n",
        "    interArea = max(0, xRight - xLeft + 1) * max(0, yRight - yLeft + 1)\n",
        "    # compute the area of both the prediction and ground-truthrectangles\n",
        "    boxAArea = (regA.xmax - regA.xmin + 1) * (regA.ymax - regA.ymin + 1)\n",
        "    boxBArea = (regB.xmax - regB.xmin + 1) * (regB.ymax - regB.ymin + 1)\n",
        "\n",
        "    # compute the intersection over union by taking the intersection\n",
        "    # area and dividing it by the sum of prediction + ground-truth\n",
        "    # areas - the interesection area\n",
        "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
        "\n",
        "    # return the intersection over union value\n",
        "    return iou\n",
        "\n",
        "\n",
        "def GetFiles(Folders, ext):\n",
        "    Files = []\n",
        "    for folder in Folders:\n",
        "        files = glob.glob(folder + '/*.' + ext)\n",
        "        files.sort()\n",
        "        Files.extend(files)\n",
        "    return Files\n",
        "\n",
        "def ResizeImg(img, height, width):\n",
        "    img_h, img_w = img.shape[0], img.shape[1]\n",
        "    scale = min(float(height) / img_h, float(width) / img_w)\n",
        "\n",
        "    img = cv2.resize(img, (int(scale*img_w), (int(scale*img_h))))\n",
        "    if img.shape[1] < width:\n",
        "        img = cv2.copyMakeBorder(img, 0, 0, 0, width - img.shape[1], cv2.BORDER_REPLICATE)\n",
        "    if img.shape[0] < height:\n",
        "        img = cv2.copyMakeBorder(img, 0, height - img.shape[0], 0, 0, cv2.BORDER_REPLICATE)\n",
        "\n",
        "    if img.ndim < 3:\n",
        "        img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "    return img, scale\n",
        "\n",
        "def Binary(ImgIn):\n",
        "    if ImgIn.shape[-1] == 3:\n",
        "      gray = cv2.cvtColor(ImgIn, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "      gray = ImgIn[...,0]\n",
        "\n",
        "    #ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 9)\n",
        "\n",
        "    return thresh\n",
        "\n",
        "def ViewImgs(Imgs):\n",
        "    fig = plt.figure(figsize=(15, 15))\n",
        "    for i in range(len(Imgs)):\n",
        "        plt.subplot(1, len(Imgs), i+1)\n",
        "        if Imgs[i].ndim == 3:\n",
        "            if  Imgs[i].shape[-1] == 3:\n",
        "              plt.imshow(Imgs[i])\n",
        "            else:\n",
        "              plt.imshow(Imgs[i][...,0], cmap='gray', vmin=0, vmax=255)\n",
        "        else:\n",
        "            plt.imshow(Imgs[i], cmap='gray', vmin=0, vmax=255)\n",
        "    plt.show()\n",
        "\n",
        "def SaveErrs(Errs, FileName, ErrImgs_H=2048, ErrImgs_W=1024):\n",
        "    print('SaveErrs: ', len(Errs))\n",
        "    ErrImgs = np.zeros((ErrImgs_H, ErrImgs_W, 3), np.uint8)\n",
        "    ErrX, ErrY = 0, 0\n",
        "    ErrH = 0\n",
        "    m = 3\n",
        "    for err in Errs:\n",
        "        rgH, rgW = err.shape[0], err.shape[1]\n",
        "\n",
        "        if ErrX + rgW > ErrImgs_W:\n",
        "            # next line\n",
        "            ErrX = 0\n",
        "            ErrY += ErrH + m\n",
        "            ErrH = 0\n",
        "\n",
        "        if ErrY + rgH < ErrImgs_H and ErrX + rgW < ErrImgs_W:\n",
        "            ErrImgs[ErrY:ErrY+rgH, ErrX:ErrX+rgW,...] = err\n",
        "            ErrX += rgW + m\n",
        "            if ErrH < rgH:\n",
        "                ErrH = rgH\n",
        "\n",
        "    SaveImgs([ErrImgs], FileName)\n",
        "\n",
        "\n",
        "def SaveImgs(Imgs, FileName):\n",
        "    for i, img in enumerate(Imgs):\n",
        "      cv2.imwrite(FileName+str(i)+'.png', img)\n",
        "\n",
        "\n",
        "def MasksImg(masks, img=None):\n",
        "    masks_img = colour_code_segmentation(reverse_one_hot(masks), MaxClass=masks.shape[-1]-1)\n",
        "    # resize mask\n",
        "    if img is not None:\n",
        "        if img.shape[0] != masks_img.shape[0] or img.shape[1] != masks_img.shape[1]:\n",
        "            #masks_img,_ = ResizeImg(masks_img, img.shape[0], img.shape[1])\n",
        "            img,_ = ResizeImg(img, masks_img.shape[0], masks_img.shape[1])\n",
        "        masks_img = ((0.5 * img) + (0.5 * masks_img)).astype(\"uint8\")\n",
        "        masks_img = np.minimum(masks_img, img)\n",
        "\n",
        "    return masks_img\n",
        "\n",
        "\n",
        "def hex_to_double(hStr):\n",
        "    return struct.unpack(\"d\", struct.pack(\"Q\",int(\"0x\"+hStr, 16)))[0]\n",
        "\n",
        "# adjust ground truth\n",
        "def AdjustGTs(regions, bw):\n",
        "  for i, rg in enumerate(regions):\n",
        "      regions[i] = AdjustGT(rg, bw)\n",
        "  return regions\n",
        "\n",
        "\n",
        "def AdjustGT(rg, bw):\n",
        "    # left-right\n",
        "    m = 4\n",
        "    rg.xmin -= m\n",
        "    rg.xmax += m\n",
        "    roi = bw[rg.ymin:rg.ymax, rg.xmin:rg.xmax]\n",
        "    hist = np.sum((255-roi)/255,axis=0)\n",
        "    len_h = len(hist)\n",
        "\n",
        "    # find the closest white line\n",
        "    left_ws = np.array([i for i in range(0,2*m) if (hist[i] == 0 and i < len_h//2)])\n",
        "    right_ws = np.array([i for i in range(len_h-2*m, len_h) if (hist[i] == 0 and i > len_h//2)])\n",
        "\n",
        "    left, right = m, len_h-m\n",
        "    if len(left_ws) > 0:\n",
        "        left = min(left_ws, key=lambda x:abs(x-left))\n",
        "    if len(right_ws) > 0:\n",
        "        right = min(right_ws, key=lambda x:abs(x-right))\n",
        "\n",
        "\n",
        "    while left < right and hist[left] == 0:\n",
        "        left += 1\n",
        "    left -= 1\n",
        "    while right > left and hist[right] == 0:\n",
        "        right -= 1\n",
        "    right += 1\n",
        "\n",
        "    rg.xmin += left\n",
        "    rg.xmax -= (len_h - right)\n",
        "\n",
        "    # top-bottom\n",
        "    m = 8\n",
        "    rg.ymin -= m\n",
        "    rg.ymax += m\n",
        "    roi = bw[rg.ymin:rg.ymax, rg.xmin:rg.xmax]\n",
        "    hist = np.sum((255-roi)/255,axis=1)\n",
        "    len_h = len(hist)\n",
        "\n",
        "    # find the closest white line\n",
        "    top_ws = np.array([i for i in range(0,2*m) if (hist[i] == 0 and i < len_h//2)])\n",
        "    bot_ws = np.array([i for i in range(len_h-2*m, len_h) if (hist[i] == 0 and i > len_h//2)])\n",
        "\n",
        "    top, bot = m, len_h-m\n",
        "    if len(top_ws) > 0:\n",
        "        top = min(top_ws, key=lambda x:abs(x-top))\n",
        "    if len(bot_ws) > 0:\n",
        "        bot = min(bot_ws, key=lambda x:abs(x-bot))\n",
        "\n",
        "    while top < bot and hist[top] == 0:\n",
        "        top += 1\n",
        "    top -= 1\n",
        "    while bot > top and hist[bot] == 0:\n",
        "        bot -= 1\n",
        "    bot +=1\n",
        "\n",
        "    rg.ymin += top\n",
        "    rg.ymax -= (len_h - bot)\n",
        "\n",
        "    return rg\n",
        "\n",
        "# data normalization\n",
        "Norm = lambda x: np.float32(x)/np.max(x)\n",
        "\n",
        "class InstanceNormalization(tf.keras.layers.Layer):\n",
        "    \"\"\"Instance Normalization Layer (https://arxiv.org/abs/1607.08022).\"\"\"\n",
        "    def __init__(self, epsilon=1e-5):\n",
        "        super(InstanceNormalization, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.scale = self.add_weight(name='scale', shape=input_shape[-1:],\n",
        "                                     initializer=tf.random_normal_initializer(1., 0.02),\n",
        "                                     trainable=True)\n",
        "\n",
        "        self.offset = self.add_weight(name='offset', shape=input_shape[-1:], initializer='zeros',\n",
        "                                      trainable=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
        "        inv = tf.math.rsqrt(variance + self.epsilon)\n",
        "        normalized = (x - mean) * inv\n",
        "        return self.scale * normalized + self.offset\n",
        "\n",
        "\n",
        "def UpScaling(x, scale):\n",
        "    x = UpSampling2D(size=[scale, scale], interpolation='bilinear')(x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "ywdlKTNqV2yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data label"
      ],
      "metadata": {
        "id": "_Vst8dGOV6j9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# single-label masks\n",
        "def Reg2MaskSL(Regions, img):\n",
        "    img_h, img_w = img.shape[0:2]\n",
        "    seg_bg = (np.zeros((img_h, img_w), np.uint8) * 255)\n",
        "    seg_masks = []\n",
        "    for c in range(num_classes):\n",
        "        # class mask\n",
        "        mask_c = np.zeros((img_h, img_w), np.uint8)\n",
        "        for reg in Regions:\n",
        "            if int(reg.tag) == c:\n",
        "                mask_c[reg.ymin:reg.ymax, reg.xmin:reg.xmax] = 255\n",
        "        # augmented mask\n",
        "        seg_masks.append(mask_c)\n",
        "        seg_bg = np.maximum(seg_bg, mask_c)\n",
        "\n",
        "    # all classes\n",
        "    seg_masks.append(255 - seg_bg)\n",
        "\n",
        "    return np.stack(seg_masks, axis=-1)\n",
        "\n",
        "\n",
        "# multiple-label masks\n",
        "def Reg2MaskML(Regions, bw):\n",
        "    img_h, img_w = bw.shape[0:2]\n",
        "    seg_fg = (np.zeros((img_h, img_w), np.uint8) * 255)\n",
        "    det_fg = (np.zeros((img_h, img_w), np.uint8) * 255)\n",
        "\n",
        "    seg_masks, detect_masks = [], []\n",
        "    for c in range(num_classes):\n",
        "        # class mask\n",
        "        mask_c = np.zeros((img_h, img_w), np.uint8)\n",
        "        for reg in Regions:\n",
        "            if int(reg.tag) == c:\n",
        "                mask_c[reg.ymin:reg.ymax, reg.xmin:reg.xmax] = 255\n",
        "\n",
        "        # augmented mask\n",
        "        fg_c = mask_c\n",
        "        margin = 4\n",
        "        if c == 1 or c == 0:\n",
        "            fg_c = np.uint8(((255-bw)*(mask_c==255)))\n",
        "            fg_c = cv2.dilate(fg_c, np.ones((2*margin+1, 2*margin+1), np.uint8))\n",
        "            fg_c = cv2.morphologyEx(fg_c, cv2.MORPH_CLOSE, np.ones((2*margin+1, 4*margin+1), np.uint8))\n",
        "            fg_c *= (mask_c==255)\n",
        "\n",
        "        # detection mask\n",
        "        det_fg = np.maximum(det_fg, fg_c)\n",
        "\n",
        "        # segmentation mask\n",
        "        fg_c = mask_c\n",
        "        seg_masks.append(fg_c)\n",
        "        seg_fg = np.maximum(seg_fg, fg_c)\n",
        "\n",
        "    # all classes\n",
        "    seg_masks.append(255 - seg_fg)\n",
        "    detect_masks.append(det_fg)\n",
        "    detect_masks.append(255 - det_fg)\n",
        "\n",
        "    AllMask = [det_fg]\n",
        "    AllMask.extend(seg_masks)\n",
        "\n",
        "    #return np.stack(seg_masks, axis=-1), np.stack(detect_masks, axis=-1)\n",
        "    return np.stack(AllMask, axis=-1), np.stack(detect_masks, axis=-1)\n",
        "\n",
        "\n",
        "def ViewData(data_fn, LoadDataFunct):\n",
        "    img, y_seg, y_detect, RegionsGT = MEDLoadData(data_fn, LoadDataFunct, INPUT_H, INPUT_W, INPUT_C)\n",
        "\n",
        "    y_img = img\n",
        "    if img.shape[-1] == 1:\n",
        "        y_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    for rg in RegionsGT:\n",
        "        cv2.rectangle(y_img, (int(rg.xmin), int(rg.ymin)), (int(rg.xmax), int(rg.ymax)), Colors[int(rg.tag)], 2)\n",
        "\n",
        "    y_sseg = Reg2MaskSL(RegionsGT, img)\n",
        "    y_sseg_img = MasksImg(y_sseg, img)\n",
        "\n",
        "    y_seg_img = MasksImg(y_seg, img)\n",
        "    y_det_img = MasksImg(y_detect, img)\n",
        "\n",
        "    cv2_imshow(y_img)\n",
        "    #cv2_imshow(y_sseg_img)\n",
        "    #cv2_imshow(y_det_img)\n",
        "    #cv2_imshow(y_seg_img)\n",
        "    ViewImgs([y_img, y_det_img, y_seg_img])\n",
        "\n",
        "\n",
        "def MEDLoadData(data_fn, LoadDataFunct, img_h=0, img_w=0, img_c=0):\n",
        "    # image and GT\n",
        "    img, RegionsGT = LoadDataFunct(data_fn)\n",
        "    if img is not None:\n",
        "        # size normalize\n",
        "        if img_h > 0 and img_w > 0:\n",
        "            img, scale = ResizeImg(img, img_h, img_w)\n",
        "\n",
        "            for i, r in enumerate(RegionsGT):\n",
        "                r.xmin = int(r.xmin*scale)\n",
        "                r.xmax = int(r.xmax*scale)\n",
        "                r.ymin = int(r.ymin*scale)\n",
        "                r.ymax = int(r.ymax*scale)\n",
        "                RegionsGT[i] = r\n",
        "\n",
        "        # adjust ground truth\n",
        "        bw = Binary(img)\n",
        "        RegionsGT = AdjustGTs(RegionsGT, bw)\n",
        "\n",
        "        # regions to mask\n",
        "        y_seg, y_detect = Reg2MaskML(RegionsGT, bw)\n",
        "\n",
        "        if img_c == 1:\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "\n",
        "        return img, y_seg, y_detect, RegionsGT\n",
        "\n",
        "    return None, None, None, None"
      ],
      "metadata": {
        "id": "VF5gfRw2V_aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MEDNet"
      ],
      "metadata": {
        "id": "o5fI19h2WB37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MEDNet(input_shape, nClass, nFeatures=128,\n",
        "           scale1=1, scale2=3, ext=3, first_filters=32, nConv=3):\n",
        "    # input\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # features\n",
        "    features = FeatExtractor(inputs, depth=scale2+ext, first_filters=first_filters, nConv=nConv)\n",
        "    s1_feats, s2_feats = [], []\n",
        "    for i in range(ext):\n",
        "        s1_feats.append(UpScaling(features[scale1+i], 2**(i+1)))\n",
        "        s2_feats.append(UpScaling(features[scale2+i], 2**(i+1)))\n",
        "\n",
        "    s1_feats = Concatenate()(s1_feats)\n",
        "    s1_feats = ConvBlocks(s1_feats, nFeatures, kernel_size=1, stride=1, nConv=1)\n",
        "    s2_feats = Concatenate()(s2_feats)\n",
        "    s2_feats = ConvBlocks(s2_feats, nFeatures, kernel_size=1, stride=1, nConv=1)\n",
        "\n",
        "    # scale1 detection map\n",
        "    s1_feats, s1_map = SegHead(s1_feats, nFeatures, out_ch=2, nConv=0)\n",
        "    s1_map = Activation('sigmoid', name=\"y1\")(s1_map)\n",
        "\n",
        "    # scale2 segmentation map\n",
        "    s2_feats, s2_map = SegHead(s2_feats, nFeatures, out_ch=nClass+2, nConv=0)\n",
        "    s2_map = Activation('sigmoid', name=\"y2\")(s2_map)\n",
        "\n",
        "    # combined feature maps\n",
        "    s2_feats = UpScaling(s2_feats, 2 ** (scale2 - scale1))\n",
        "    s12_feats = Concatenate()([s1_feats, s2_feats])\n",
        "    s12_feats = ConvBlocks(s12_feats, nFeatures, kernel_size=1, stride=1, nConv=1)\n",
        "\n",
        "    # final segmentation map\n",
        "    s12_feats, seg_map = SegHead(s12_feats, nFeatures, out_ch=nClass+2, nConv=3)\n",
        "    seg_map = UpScaling(seg_map, 2 ** scale1)\n",
        "    seg_map = Activation('sigmoid', name=\"y\")(seg_map)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=[seg_map, s1_map, s2_map])\n",
        "\n",
        "\n",
        "def SegHead(x, filters, out_ch=1, nConv=1, DropRate=0.2):\n",
        "    if nConv > 0:\n",
        "        x = ConvBlocks(x, filters, kernel_size=(3,3), nConv=nConv, DropRate=DropRate)\n",
        "\n",
        "    seg_map = Conv2D(out_ch, kernel_size=3, strides=1, padding='same')(x)\n",
        "    return x, seg_map\n",
        "\n",
        "\n",
        "def FeatExtractor(x, depth=5, first_filters=32, nConv=2):\n",
        "    features = []\n",
        "    filters = first_filters\n",
        "    for i in range(depth):\n",
        "        if i == 0:\n",
        "            x = ConvBlocks(x, filters, kernel_size=(7,5), stride=2, nConv=nConv)\n",
        "            filters *= 2\n",
        "            nConv += 1\n",
        "        else:\n",
        "            x = K_ConvBlocks(x, filters, [(3, 3), (3, 7)], nConv=nConv)\n",
        "            x = MaxPooling2D()(x)\n",
        "\n",
        "        features.append(x)\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "# convolution blocks\n",
        "def K_ConvBlocks(x, filters, kernel_sizes, nConv=2, NormType='instance', DropRate=0.2):\n",
        "    maps = []\n",
        "    for k in kernel_sizes:\n",
        "        m = ConvBlocks(x, filters//2, kernel_size=k, stride=1, nConv=nConv, NormType=NormType, DropRate=DropRate)\n",
        "        maps.append(m)\n",
        "    map = Concatenate()(maps)\n",
        "    map = ConvBlocks(map, filters, kernel_size=1, stride=1, nConv=1, NormType=NormType, DropRate=DropRate)\n",
        "\n",
        "    return map\n",
        "\n",
        "def ConvBlocks(x, filters, kernel_size=(3, 3), dilation_rate=1, stride=1, nConv=1, NormType='instance', DropRate=0.2):\n",
        "    # first conv\n",
        "    x = Conv_BN_Act(filters, kernel_size=kernel_size, dilation_rate=dilation_rate,stride=stride,\n",
        "                    NormType=NormType, DropRate=DropRate)(x)\n",
        "    # stride-1 convolution\n",
        "    for i in range(1, nConv):\n",
        "        x = Conv_BN_Act(filters, kernel_size=kernel_size, stride=1, NormType=NormType, DropRate=DropRate)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "# Basic convolution block\n",
        "def Conv_BN_Act(filters, kernel_size=(3, 3), dilation_rate=(1, 1), stride=1, NormType='instance', DropRate=0.2):\n",
        "    f = Sequential()\n",
        "\n",
        "    f.add(Conv2D(filters, kernel_size, strides=stride, dilation_rate=dilation_rate, padding='same', use_bias=False))\n",
        "\n",
        "    if NormType.lower() == 'batch':\n",
        "        f.add(BatchNormalization())\n",
        "    elif NormType.lower() == 'instance':\n",
        "        f.add(InstanceNormalization())\n",
        "\n",
        "    f.add(ReLU())\n",
        "\n",
        "    if DropRate > 0.0:\n",
        "        f.add(Dropout(DropRate))\n",
        "\n",
        "    return f\n"
      ],
      "metadata": {
        "id": "YiEWnRFlWFEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defaut variables\n",
        "INPUT_H, INPUT_W, INPUT_C = 1472, 1024, 1\n",
        "input_shape = [INPUT_H, INPUT_W, INPUT_C]\n",
        "num_classes = 2\n",
        "\n",
        "scale1, scale2, ext = 1, 3, 3\n",
        "nConv, first_filters = 3, 64\n",
        "nFeatures = 128\n",
        "\n",
        "#act_funct='softmax'\n",
        "#loss_funct = 'categorical_crossentropy'\n",
        "#metric = 'accuracy'\n",
        "\n",
        "act_funct='sigmoid'\n",
        "loss_funct = 'binary_crossentropy'\n",
        "metric = 'binary_accuracy'\n",
        "\n",
        "Losses = {\n",
        "    \"y\": loss_funct,\n",
        "    \"y1\": loss_funct,\n",
        "    \"y2\": loss_funct,\n",
        "}\n",
        "\n",
        "def BuildModel():\n",
        "    model = MEDNet(input_shape, num_classes, nFeatures=nFeatures,\n",
        "                   scale1=scale1, scale2=scale2, ext=ext, first_filters=first_filters, nConv=nConv)\n",
        "\n",
        "    #optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001)\n",
        "\n",
        "    #radam = tfa.optimizers.RectifiedAdam()\n",
        "    #ranger = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n",
        "    #optimizer = ranger\n",
        "\n",
        "    model.compile(loss=Losses, optimizer=optimizer, metrics=[metric])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# test\n",
        "model = BuildModel()\n",
        "model.summary()\n",
        "#tf.keras.utils.plot_model(model, show_shapes=True)\n"
      ],
      "metadata": {
        "id": "-nNAbAXLWG4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test API"
      ],
      "metadata": {
        "id": "hqG4rkS5WJhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_W, MIN_H = 5, 7\n",
        "\n",
        "def Predict(model, img):\n",
        "    x = img\n",
        "    if INPUT_C == 1 and len(x.shape) == 3 and x.shape[-1] == 3:\n",
        "        x = cv2.cvtColor(x, cv2.COLOR_RGB2GRAY)\n",
        "    if x.shape[0] != INPUT_H or x.shape[1] != INPUT_W:\n",
        "        x, scale = ResizeImg(x, INPUT_H, INPUT_W)\n",
        "    x = Norm(x)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    return model.predict(x, verbose=0)\n",
        "\n",
        "\n",
        "def SampleTest(model, img_fn, num_classes=1, FileName=None, thresh=0.7, debug=True):\n",
        "    Imgs = []\n",
        "    # load data\n",
        "    #img, all_masks, RegionsGT = LoadData(img_fn, INPUT_H, INPUT_W, INPUT_C)\n",
        "    img, seg_masks, det_masks, RegionsGT = MEDLoadData(img_fn, LoadDataFunct, INPUT_H, INPUT_W, INPUT_C)\n",
        "    if img is None:\n",
        "       return None, None, None, None, None\n",
        "\n",
        "    y_img = MasksImg(seg_masks, img)\n",
        "    #y_img = MasksImg(seg_masks, 255-img)\n",
        "    #ViewImgs([y_img])\n",
        "\n",
        "    # predict\n",
        "    #yy_seg, yy_seg2 = Predict(model, img)\n",
        "    yy_seg, yy_seg1, yy_seg2 = Predict(model, img)\n",
        "    yy_seg = yy_seg[0]\n",
        "    yy_det_masks = yy_seg1[0]\n",
        "    yy_seg[yy_seg >= 0.5] = 1\n",
        "\n",
        "    # detection\n",
        "    #RegionsPD = GetRegionsPD(yy_seg, num_classes, img)\n",
        "    RegionsPD = GetRegionsPD(yy_seg[...,1:], num_classes, img)\n",
        "    #RegionsPD = GetRegionsPD(yy_seg[...,1:], num_classes, 255-img)\n",
        "\n",
        "    # performance\n",
        "    IoUs, TPRegs, nPos, nPred, nTP = MatchRegs(RegionsGT, RegionsPD, num_classes, thresh)\n",
        "\n",
        "    # errors\n",
        "    yy_seg[yy_seg >= 0.5] = 1\n",
        "    #yy_img = MasksImg(yy_seg, 255-img)\n",
        "    yy_img = MasksImg(yy_seg, img)\n",
        "\n",
        "    for rg in RegionsGT:\n",
        "        #cv2.rectangle(yy_img, (int(rg.xmin), int(rg.ymin)), (int(rg.xmax), int(rg.ymax)), [0,0,255], 1)\n",
        "        cv2.rectangle(yy_img, (int(rg.xmin), int(rg.ymin)), (int(rg.xmax), int(rg.ymax)), Colors[int(rg.tag)+1], 1)\n",
        "    for rg in RegionsPD:\n",
        "        cv2.rectangle(yy_img, (int(rg.xmin), int(rg.ymin)), (int(rg.xmax), int(rg.ymax)), Colors[int(rg.tag)+1], 1)\n",
        "\n",
        "    MissErrs, WrongErrs = [], []\n",
        "    m = 8\n",
        "    for (iou, rg) in zip(IoUs, RegionsGT):\n",
        "        if iou < thresh:\n",
        "            cv2.putText(yy_img, \"{:.1f}\".format(iou*100), (rg.xmin, rg.ymin-3), cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,0,255), 1)\n",
        "            # err image\n",
        "            if int(rg.tag) == 0:\n",
        "                errImg = yy_img[rg.ymin-m:rg.ymax+m, rg.xmin-m:rg.xmax+m,...]\n",
        "                MissErrs.append(errImg)\n",
        "\n",
        "    IoUs2, TPRegs2, nPos2, nPred2, nTP2 = MatchRegs(RegionsPD, RegionsGT, num_classes, thresh)\n",
        "    for (iou, rg) in zip(IoUs2, RegionsPD):\n",
        "        #cv2.rectangle(yy_img, (int(rg.xmin), int(rg.ymin)), (int(rg.xmax), int(rg.ymax)), Colors[int(rg.tag)+1], 1)\n",
        "        if iou < thresh:\n",
        "            cv2.putText(yy_img, \"{:.1f}\".format(iou*100), (rg.xmin, rg.ymin-3), cv2.FONT_HERSHEY_SIMPLEX, 0.3, Colors[int(rg.tag)], 1)\n",
        "            if int(rg.tag) == 0:\n",
        "                errImg = yy_img[rg.ymin-m:rg.ymax+m, rg.xmin-m:rg.xmax+m,...]\n",
        "                WrongErrs.append(errImg)\n",
        "\n",
        "    #if debug:\n",
        "    #if nTP[0] != nPos[0] or nTP[0] != nPred[0] or nTP[1] != nPos[1] or nTP[1] != nPred[1]:\n",
        "    #if debug or nTP[1] != nPos[1] or nTP[1] != nPred[1]:\n",
        "    #if True:\n",
        "    if debug and ((nTP[0] != nPos[0] or nTP[0] != nPred[0]) or (num_classes > 1  and (nTP[1] != nPos[1] or nTP[1] != nPred[1]))):\n",
        "        print(nPos, nPred, nTP)\n",
        "        #Masks = []\n",
        "        #for i in range(yy_seg.shape[-1]):\n",
        "        #    Masks.append(yy_seg[...,i]*255)\n",
        "        #ViewImgs(Masks)\n",
        "\n",
        "        #cv2_imshow(y_img)\n",
        "        cv2_imshow(yy_img)\n",
        "        #ViewImgs([yy_img])\n",
        "        #y_img = MasksImg(all_masks, img)\n",
        "        #y_det_img = MasksImg(det_masks, img)\n",
        "        #yy_det_img = MasksImg(yy_det_masks, img)\n",
        "        #ViewImgs([y_img, yy_img, yy_det_img])\n",
        "        #ViewImgs([y_det_img, yy_det_img])\n",
        "        if FileName is not None:\n",
        "            SaveImgs([yy_img], FileName)\n",
        "\n",
        "    return nPos, nPred, nTP, MissErrs, WrongErrs\n",
        "\n",
        "\n",
        "def ModelTest(model, FileNames, num_classes, thresh=0.7, debug=False):\n",
        "    print(\"Testing...\")\n",
        "    nPositive = np.zeros(num_classes)\n",
        "    nPredicted = np.zeros(num_classes)\n",
        "    nTruePos = np.zeros(num_classes)\n",
        "    MissErrs, WrongErrs = [], []\n",
        "    for (idx, img_fn) in enumerate(FileNames):\n",
        "        nPos, nPred, nTP, Miss, Wrong = SampleTest(model, img_fn, num_classes=num_classes, thresh=thresh, debug=debug)\n",
        "        if nPos is not None:\n",
        "            nPositive += nPos\n",
        "            nPredicted += nPred\n",
        "            nTruePos += nTP\n",
        "\n",
        "            # inspect result\n",
        "            if (nTP[0] != nPos[0] or nTP[0] != nPred[0]) or (num_classes > 1  and (nTP[1] != nPos[1] or nTP[1] != nPred[1])):\n",
        "            #if nPos[0] != nTP[0]:\n",
        "                print(idx, nPos, nPred, nTP)\n",
        "                if len(MissErrs) < 500:\n",
        "                    MissErrs.extend(Miss)\n",
        "                if len(WrongErrs) < 500:\n",
        "                    WrongErrs.extend(Wrong)\n",
        "\n",
        "    # end of for\n",
        "    if len(FileNames) > 0:\n",
        "        Recall = nTruePos/nPositive\n",
        "        Precision = nTruePos/nPredicted\n",
        "        F1  = []\n",
        "        for i in range(len(Precision)):\n",
        "          F1.append(2*Precision[i]*Recall[i]/(Precision[i] + Recall[i]) if Precision[i] + Recall[i] > 0 else 0)\n",
        "\n",
        "        print(\"Class: Recall, Precision, F1\")\n",
        "        for i in range(num_classes):\n",
        "            #print(\"%s: %.4f, %.4f, %.4f\" % (class_names[i], Recall[i], Precision[i], F1[i]))\n",
        "            print(\"%s: %.2f (%.2f, %.2f)\" % (class_names[i], F1[i]*100, Precision[i]*100, Recall[i]*100))\n",
        "\n",
        "\n",
        "    print(nPositive, nPredicted, nTruePos)\n",
        "    nTP = sum(nTruePos)\n",
        "    nPr = sum(nPredicted)\n",
        "    nPos = sum(nPositive)\n",
        "    P, R = nTP / nPr, nTP / nPos\n",
        "    F = 2*P*R/(P + R)\n",
        "    print(\"All: %.2f (%.2f, %.2f)\" % (F*100, P*100, R*100))\n",
        "\n",
        "    # errors\n",
        "    SaveErrs(MissErrs, 'MissErrs')\n",
        "    SaveErrs(WrongErrs, 'WrongErrs')\n",
        "\n",
        "    #return nPositive, nPredicted, nTruePos, MissErrs, WrongErrs\n",
        "\n",
        "\n",
        "def GetRegionsPD(masks, nClass, x):\n",
        "    code = reverse_one_hot(masks)\n",
        "    x_bw = Binary(x)\n",
        "    Regions = []\n",
        "    for c in range(nClass):\n",
        "        #c_mask = np.uint8((code == c))*255\n",
        "        c_mask = np.uint8((masks[...,c] >= 0.5))*255\n",
        "\n",
        "        #c_mask = cv2.dilate(c_mask, np.ones((4, 4), np.uint8))\n",
        "        #if c == 1: # isolated formula\n",
        "        #  c_mask = cv2.morphologyEx(c_mask, cv2.MORPH_CLOSE, np.ones((7,31),np.uint8))\n",
        "        #elif c == 0: # embeded formula\n",
        "        #  c_mask = cv2.morphologyEx(c_mask, cv2.MORPH_CLOSE, np.ones((3, 7), np.uint8))\n",
        "\n",
        "        #ViewImgs([c_mask])\n",
        "\n",
        "        nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(c_mask)\n",
        "        c_regions = []\n",
        "        for i in range(1, nlabels):\n",
        "            l_mask = (labels == i).astype(\"uint8\") * 255\n",
        "            l, t = stats[i, cv2.CC_STAT_LEFT], stats[i, cv2.CC_STAT_TOP]\n",
        "            w, h = stats[i, cv2.CC_STAT_WIDTH], stats[i, cv2.CC_STAT_HEIGHT]\n",
        "            r, b = l + w, t + h\n",
        "\n",
        "            if (c == 0 and w >= MIN_W and h >= MIN_H) or (c == 1 and w > 32 and h >= 16):\n",
        "                rg = Region(str(c), l-2, t-2, r+2, b+2)\n",
        "                if c == 0 and rg.ymax - rg.ymin > 30 and rg.xmax - rg.xmin > 30:\n",
        "                #if False:\n",
        "                    rgs = SplitFormula(rg, x_bw, l_mask)\n",
        "                    if len(rgs) > 1:\n",
        "                        c_regions.extend(rgs)\n",
        "                    else:\n",
        "                        c_regions.append(rg)\n",
        "                else:\n",
        "                    c_regions.append(rg)\n",
        "\n",
        "        #c_mask = cv2.dilate(c_mask, np.ones((3, 3), np.uint8))\n",
        "        c_regions = AdjustPDs(c_regions, x_bw, c_mask)\n",
        "        Regions.extend(c_regions)\n",
        "\n",
        "    #ViewImgs([x_img])\n",
        "    Regions = PostProcess(Regions, x_bw)\n",
        "\n",
        "    return Regions\n",
        "\n",
        "def SplitFormula(reg, x, mask):\n",
        "    #msk = (mask[reg.ymin:reg.ymax, reg.xmin:reg.xmax]*255).astype(np.uint8)\n",
        "    msk = mask[reg.ymin:reg.ymax, reg.xmin:reg.xmax]\n",
        "    img = x[reg.ymin:reg.ymax, reg.xmin:reg.xmax]\n",
        "    img = 255-(255-img)*(msk==255)\n",
        "\n",
        "    #ViewImgs([msk, img])\n",
        "\n",
        "    img2 = cv2.erode(img,np.ones((1,7)))\n",
        "    img3 = cv2.dilate(img2,np.ones((3,1)))\n",
        "    hist = np.sum((255-img3)/255,axis=1)\n",
        "\n",
        "    #plt.figure().set_figheight(2.2)\n",
        "    #ys = [y for y in range(len(hist))]\n",
        "    #plt.gca().invert_yaxis()\n",
        "    #plt.plot(hist, ys)\n",
        "\n",
        "    #plt.show()\n",
        "\n",
        "    s = 16\n",
        "    e = len(hist) - 16\n",
        "    for i in range(s,e):\n",
        "      if hist[i] == 0:\n",
        "        msk[i,] = 0\n",
        "\n",
        "    #msk = (msk*255).astype(np.uint8)\n",
        "    new_regions = []\n",
        "    # candidate CCs\n",
        "    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(msk)\n",
        "\n",
        "    # view CCs\n",
        "    # Map component labels to hue val, 0-179 is the hue range in OpenCV\n",
        "    label_hue = np.uint8(100*labels/np.max(labels))\n",
        "    blank_ch = 255*np.ones_like(label_hue)\n",
        "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
        "\n",
        "    # Converting cvt to BGR\n",
        "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2RGB)\n",
        "\n",
        "    # set bg label to black\n",
        "    labeled_img[label_hue==0] = 0\n",
        "\n",
        "    #ViewImgs([img,labeled_img])\n",
        "\n",
        "    for i in range(1, nlabels):\n",
        "        l, t = stats[i, cv2.CC_STAT_LEFT], stats[i, cv2.CC_STAT_TOP]\n",
        "        w, h = stats[i, cv2.CC_STAT_WIDTH], stats[i, cv2.CC_STAT_HEIGHT]\n",
        "        # check and get sub-regions\n",
        "        if w >= MIN_W and h >= MIN_H:\n",
        "          l += reg.xmin\n",
        "          t += reg.ymin\n",
        "          r, b = l + w, t + h\n",
        "          rg = Region(reg.tag, l, t, r, b, None)\n",
        "          new_regions.append(rg)\n",
        "\n",
        "    #print(len(new_regions))\n",
        "    #ViewImgs([img, img2, img3, msk])\n",
        "\n",
        "    return new_regions\n",
        "\n",
        "\n",
        "# adjusted PD\n",
        "def AdjustPDs(regions, bw, mask=None):\n",
        "    for i, rg in enumerate(regions):\n",
        "      if int(rg.tag) == 0:\n",
        "        regions[i] = AdjustPD(rg, bw, mask)\n",
        "      else:\n",
        "        regions[i] = AdjustPD(rg, bw)\n",
        "\n",
        "    regions = RemoveNested(regions)\n",
        "    return regions\n",
        "\n",
        "\n",
        "def AdjustPD(rg, bw, mask=None):\n",
        "    # left-right\n",
        "    roi = bw[rg.ymin:rg.ymax, rg.xmin:rg.xmax]\n",
        "    if mask is not None:\n",
        "        msk = mask[rg.ymin:rg.ymax, rg.xmin:rg.xmax]\n",
        "        roi = 255-(255-roi)*(msk==255)\n",
        "\n",
        "    hist = np.sum((255-roi)/255,axis=0)\n",
        "    len_h = len(hist)\n",
        "\n",
        "    # find the closest white line\n",
        "    left, right = 0, len_h-1\n",
        "    while left < right and hist[left] == 0:\n",
        "        left += 1\n",
        "    left -= 1\n",
        "    while right > left and hist[right] == 0:\n",
        "        right -= 1\n",
        "    right += 1\n",
        "    rg.xmin += left\n",
        "    rg.xmax -= (len_h - right)\n",
        "\n",
        "    # top-bottom\n",
        "    roi = bw[rg.ymin:rg.ymax, rg.xmin:rg.xmax]\n",
        "    if mask is not None:\n",
        "        msk = mask[rg.ymin:rg.ymax, rg.xmin:rg.xmax]\n",
        "        roi = 255-(255-roi)*(msk==255)\n",
        "\n",
        "    #ViewImgs([roi])\n",
        "    hist = np.sum((255-roi)/255,axis=1)\n",
        "    len_h = len(hist)\n",
        "\n",
        "    # find the closest white line\n",
        "    top, bot = 0, len_h-1\n",
        "    while top < bot and hist[top] == 0:\n",
        "        top += 1\n",
        "    top -= 1\n",
        "    while bot > top and hist[bot] == 0:\n",
        "        bot -= 1\n",
        "    bot +=1\n",
        "    rg.ymin += top\n",
        "    rg.ymax -= (len_h - bot)\n",
        "\n",
        "    return rg\n",
        "\n",
        "def AdjustPD0(rg, bw, mask=None):\n",
        "    roi = bw[rg.ymin:rg.ymax, rg.xmin:rg.xmax]\n",
        "    if mask is not None:\n",
        "      msk = mask[rg.ymin:rg.ymax, rg.xmin:rg.xmax]\n",
        "      roi = 255-(255-roi)*(msk==255)\n",
        "\n",
        "    #ViewImgs([roi])\n",
        "    # top and bottom\n",
        "    hist = np.sum((255-roi)/255,axis=1)\n",
        "    top, bot = 0, len(hist)-1\n",
        "    # top\n",
        "    while top < bot:\n",
        "      if hist[top] > 0:\n",
        "        break\n",
        "      top += 1\n",
        "    # bottom\n",
        "    while bot > top:\n",
        "      if hist[bot] > 0:\n",
        "        break\n",
        "      bot -= 1\n",
        "    rg.ymax = rg.ymin + bot + 1\n",
        "    rg.ymin = rg.ymin + top\n",
        "\n",
        "    # left and right\n",
        "    hist = np.sum((255-roi)/255,axis=0)\n",
        "    left, right = 0, len(hist)-1\n",
        "    # top\n",
        "    while left < right:\n",
        "      if hist[left] > 0:\n",
        "        break\n",
        "      left += 1\n",
        "    # bottom\n",
        "    while right > left:\n",
        "      if hist[right] > 0:\n",
        "        break\n",
        "      right -= 1\n",
        "    rg.xmax = rg.xmin + right + 1\n",
        "    rg.xmin = rg.xmin + left\n",
        "\n",
        "    return rg\n",
        "\n",
        "def GetErrImgs(img, RegionsGT, RegionsPD, num_classes, thresh, debug=False):\n",
        "    if img.shape[-1] == 1:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    for rg in RegionsGT:\n",
        "      cv2.rectangle(img, (rg.xmin, rg.ymin), (rg.xmax, rg.ymax), (0,0,255), 1)\n",
        "    for rg in RegionsPD:\n",
        "      cv2.rectangle(img, (rg.xmin, rg.ymin), (rg.xmax, rg.ymax), (255,0,0), 1)\n",
        "\n",
        "    # errors\n",
        "    m = 8\n",
        "    MissErrs, WrongErrs = [], []\n",
        "    # miss errors\n",
        "    IoUs, TPRegs, nPos, nPred, nTP = MatchRegs(RegionsGT, RegionsPD, num_classes, thresh)\n",
        "    for iou, rg in zip(IoUs, RegionsGT):\n",
        "      if iou < thresh:\n",
        "        cv2.putText(img, \"{:.1f}\".format(iou*100), (rg.xmin, rg.ymin-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 1)\n",
        "\n",
        "        # err images\n",
        "        if int(rg.tag) == 0:\n",
        "            errImg = img[rg.ymin-m:rg.ymax+m, rg.xmin-m:rg.xmax+m,...]\n",
        "            MissErrs.append(errImg)\n",
        "\n",
        "    # wrong errors\n",
        "    IoUs, TPRegs, nPos, nPred, nTP = MatchRegs(RegionsPD, RegionsGT, num_classes, thresh)\n",
        "    for iou, rg in zip(IoUs, RegionsPD):\n",
        "      if iou < thresh:\n",
        "        cv2.putText(img, \"{:.1f}\".format(iou*100), (rg.xmin, rg.ymin-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1)\n",
        "\n",
        "        # err images\n",
        "        errImg = img[rg.ymin-m:rg.ymax+m, rg.xmin-m:rg.xmax+m,...]\n",
        "        if int(rg.tag) == 0:\n",
        "            errImg = img[rg.ymin-m:rg.ymax+m, rg.xmin-m:rg.xmax+m,...]\n",
        "            WrongErrs.append(errImg)\n",
        "\n",
        "    Imgs = [img]\n",
        "\n",
        "    return Imgs, MissErrs, WrongErrs\n",
        "\n",
        "\n",
        "# match regions\n",
        "def MatchRegs(GTRegs, PDRegs, nClass, thresh):\n",
        "    IoUs = []\n",
        "    TPRegs = []\n",
        "    for reg in GTRegs:\n",
        "      MaxIoU = Match(reg, PDRegs)\n",
        "      IoUs.append(MaxIoU)\n",
        "\n",
        "      if MaxIoU >= thresh:\n",
        "        TPRegs.append(reg)\n",
        "\n",
        "    nPos = np.zeros(nClass)\n",
        "    nPD = np.zeros(nClass)\n",
        "    nTP = np.zeros(nClass)\n",
        "    for i in range(nClass):\n",
        "      nPos[i] = len([r for r in GTRegs if int(r.tag) == i])\n",
        "      nPD[i]  = len([r for r in PDRegs if int(r.tag) == i])\n",
        "      nTP[i]  = len([r for r in TPRegs if int(r.tag) == i])\n",
        "\n",
        "    return IoUs, TPRegs, nPos, nPD, nTP\n",
        "\n",
        "def Match(rg, Regs):\n",
        "    MaxIoU = 0.0\n",
        "    for reg in Regs:\n",
        "      if rg.tag == reg.tag:\n",
        "        iou = bb_iou(rg, reg)\n",
        "        if MaxIoU < iou:\n",
        "          MaxIoU = iou\n",
        "\n",
        "    return MaxIoU\n",
        "\n",
        "def PostProcess(Regions, bw):\n",
        "    # remove small and nested\n",
        "    Regions = RemoveSmall(Regions)\n",
        "    Regions = RemoveNested(Regions)\n",
        "\n",
        "    # group isolated\n",
        "    Regions = GroupIsolated(Regions, bw)\n",
        "\n",
        "    # combine embbed isolated\n",
        "    Regions = MergeEI(Regions, bw)\n",
        "\n",
        "    return Regions\n",
        "\n",
        "\n",
        "def RemoveSmall(Regions):\n",
        "    NewRegions = []\n",
        "    for rg in Regions:\n",
        "        if not IsSmall(rg):\n",
        "          NewRegions.append(rg)\n",
        "\n",
        "    return NewRegions\n",
        "\n",
        "MIN_EMB_WIDTH, MIN_EMB_HEIGHT = 6, 8\n",
        "MIN_ISO_WIDTH, MIN_ISO_HEIGHT = 32, 16\n",
        "def IsSmall(rg):\n",
        "    if (int(rg.tag) == 0 and (rg.xmax - rg.xmin < MIN_EMB_WIDTH or rg.ymax - rg.ymin < MIN_EMB_HEIGHT)) or \\\n",
        "       (int(rg.tag) == 1 and (rg.xmax - rg.xmin < MIN_ISO_WIDTH or rg.ymax - rg.ymin < MIN_ISO_HEIGHT)):\n",
        "       return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def RemoveNested(Regions):\n",
        "    NewRegions = []\n",
        "    for i in range(len(Regions)):\n",
        "        if not IsNested(i, Regions):\n",
        "          NewRegions.append(Regions[i])\n",
        "\n",
        "    return NewRegions\n",
        "\n",
        "def IsNested(i, regions):\n",
        "    ri = regions[i]\n",
        "    for j in range(len(regions)):\n",
        "      if j != i:\n",
        "        rj = regions[j]\n",
        "        if rj.xmin <= ri.xmin+2 and ri.xmax <= rj.xmax+2 and rj.ymin <= ri.ymin+2 and ri.ymax <= rj.ymax+2:\n",
        "          return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def IsIsoMergeable(rg1, rg2, bw=None):\n",
        "    return IsHorOverlapB(rg1, rg2) and IsVerOverlap(rg1, rg2, 96)\n",
        "\n",
        "def GroupIsolated(Regions, bw):\n",
        "    NewRegions = []\n",
        "    nReg = len(Regions)\n",
        "    for (i,rg) in enumerate(Regions):\n",
        "        if rg.tag == '1':\n",
        "            for j in range(i+1, nReg):\n",
        "                if Regions[j].tag == '1' and IsIsoMergeable(rg, Regions[j], bw):\n",
        "                    rg = Merge(rg, Regions[j])\n",
        "                    Regions[j].tag = '-1'\n",
        "                    break\n",
        "            NewRegions.append(rg)\n",
        "        elif rg.tag == '0':\n",
        "            NewRegions.append(rg)\n",
        "\n",
        "    return NewRegions\n",
        "\n",
        "def IsEIMergeable(rg1, rg2, bw=None):\n",
        "    return IsHorOverlapC(rg1, rg2) and IsVerOverlap(rg1, rg2)\n",
        "\n",
        "def MergeEI(Regions, bw):\n",
        "    NewRegions = []\n",
        "    nReg = len(Regions)\n",
        "    for (i,rg) in enumerate(Regions):\n",
        "        if rg.tag == '0':\n",
        "            for j in range(i+1, nReg):\n",
        "                if Regions[j].tag == '1' and IsEIMergeable(rg, Regions[j], bw):\n",
        "                    if Regions[j].xmax - Regions[j].xmin > rg.xmax - rg.xmin:\n",
        "                        rg.tag = Regions[j].tag\n",
        "                    rg = Merge(rg, Regions[j])\n",
        "                    Regions[j].tag = '-1'\n",
        "                    break\n",
        "            NewRegions.append(rg)\n",
        "        elif rg.tag == '1':\n",
        "            NewRegions.append(rg)\n",
        "\n",
        "    return NewRegions\n",
        "\n",
        "\n",
        "def Merge(rg1, rg2):\n",
        "    rg1.xmin = min(rg1.xmin, rg2.xmin)\n",
        "    rg1.ymin = min(rg1.ymin, rg2.ymin)\n",
        "    rg1.xmax = max(rg1.xmax, rg2.xmax)\n",
        "    rg1.ymax = max(rg1.ymax, rg2.ymax)\n",
        "\n",
        "    return rg1\n",
        "\n",
        "def IsHorOverlapC(rg1, rg2, d=0):\n",
        "    c1 = (rg1.ymin + rg1.ymax) // 2\n",
        "    c2 = (rg2.ymin + rg2.ymax) // 2\n",
        "    return (rg1.ymin-d <= c2 and c2 <= rg1.ymax+d) and \\\n",
        "           (rg2.ymin-d <= c1 and c1 <= rg2.ymax+d)\n",
        "\n",
        "\n",
        "def IsHorOverlapB(rg1, rg2, d=0):\n",
        "    return (rg1.ymin-d <= rg2.ymin and rg2.ymin <= rg1.ymax+d) or \\\n",
        "           (rg1.ymin-d <= rg2.ymax and rg2.ymax <= rg1.ymax+d) or \\\n",
        "           (rg2.ymin-d <= rg1.ymin and rg1.ymin <= rg2.ymax+d) or \\\n",
        "           (rg2.ymin-d <= rg1.ymax and rg1.ymax <= rg2.ymax+d)\n",
        "\n",
        "def IsVerOverlap(rg1, rg2, d=0):\n",
        "    return (rg1.xmin-d <= rg2.xmin and rg2.xmin <= rg1.xmax+d) or \\\n",
        "           (rg1.xmin-d <= rg2.xmax and rg2.xmax <= rg1.xmax+d) or \\\n",
        "           (rg2.xmin-d <= rg1.xmin and rg1.xmin <= rg2.xmax+d) or \\\n",
        "           (rg2.xmin-d <= rg1.xmax and rg1.xmax <= rg2.xmax+d)\n"
      ],
      "metadata": {
        "id": "QRglQgnNWNM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IBEM data..."
      ],
      "metadata": {
        "id": "xiPlBqHYWQsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy and decompress data\n",
        "!mkdir IBEM\n",
        "\n",
        "# train\n",
        "!mkdir IBEM/Tr00\n",
        "!mkdir IBEM/Tr00/images\n",
        "!mkdir IBEM/Tr01\n",
        "!mkdir IBEM/Tr01/images\n",
        "!mkdir IBEM/Tr10\n",
        "!mkdir IBEM/Tr10/images\n",
        "\n",
        "!unzip drive/MyDrive/Data/IBEM/Tr00/Tr00.zip -d IBEM/Tr00/images > /dev/null\n",
        "!unzip drive/MyDrive/Data/IBEM/Tr00/labels.zip -d IBEM/Tr00 > /dev/null\n",
        "\n",
        "!unzip drive/MyDrive/Data/IBEM/Tr01/Tr01.zip -d IBEM/Tr01/images > /dev/null\n",
        "!unzip drive/MyDrive/Data/IBEM/Tr01/labels.zip -d IBEM/Tr01 > /dev/null\n",
        "\n",
        "!unzip drive/MyDrive/Data/IBEM/Tr10/Tr10.zip -d IBEM/Tr10/images > /dev/null\n",
        "!unzip drive/MyDrive/Data/IBEM/Tr10/labels.zip -d IBEM/Tr10 > /dev/null\n",
        "\n",
        "# validation\n",
        "!mkdir IBEM/Va00\n",
        "!mkdir IBEM/Va00/images\n",
        "!mkdir IBEM/Va01\n",
        "!mkdir IBEM/Va01/images\n",
        "\n",
        "!unzip drive/MyDrive/Data/IBEM/Va00/Va00.zip -d IBEM/Va00/images > /dev/null\n",
        "!unzip drive/MyDrive/Data/IBEM/Va00/labels.zip -d IBEM/Va00 > /dev/null\n",
        "\n",
        "!unzip drive/MyDrive/Data/IBEM/Va01/Va01.zip -d IBEM/Va01/images > /dev/null\n",
        "!unzip drive/MyDrive/Data/IBEM/Va01/labels.zip -d IBEM/Va01 > /dev/null\n",
        "\n",
        "# test\n",
        "!mkdir IBEM/Ts00\n",
        "!mkdir IBEM/Ts00/images\n",
        "!mkdir IBEM/Ts01\n",
        "!mkdir IBEM/Ts01/images\n",
        "!mkdir IBEM/Ts10\n",
        "!mkdir IBEM/Ts10/images\n",
        "!mkdir IBEM/Ts11\n",
        "!mkdir IBEM/Ts11/images\n",
        "\n",
        "!unzip drive/MyDrive/Data/IBEM/Ts00/Ts00.zip -d IBEM/Ts00/images > /dev/null\n",
        "!unzip drive/MyDrive/Data/IBEM/Ts00/labels.zip -d IBEM/Ts00 > /dev/null\n",
        "\n",
        "!unzip drive/MyDrive/Data/IBEM/Ts01/Ts01.zip -d IBEM/Ts01/images > /dev/null\n",
        "!unzip drive/MyDrive/Data/IBEM/Ts01/labels.zip -d IBEM/Ts01 > /dev/null\n",
        "\n",
        "!unzip drive/MyDrive/Data/IBEM/Ts10/Ts10.zip -d IBEM/Ts10/images > /dev/null\n",
        "!unzip drive/MyDrive/Data/IBEM/Ts10/labels.zip -d IBEM/Ts10 > /dev/null\n",
        "\n",
        "!unzip drive/MyDrive/Data/IBEM/Ts11/Ts11.zip -d IBEM/Ts11/images > /dev/null\n",
        "!unzip drive/MyDrive/Data/IBEM/Ts11/labels.zip -d IBEM/Ts11 > /dev/null"
      ],
      "metadata": {
        "id": "7BcV5pBVWV5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Folder_Tr00 = '/content/IBEM/Tr00/images'\n",
        "Folder_Tr01 = '/content/IBEM/Tr01/images'\n",
        "Folder_Tr10 = '/content/IBEM/Tr10/images'\n",
        "\n",
        "Folder_Va00 = '/content/IBEM/Va00/images'\n",
        "Folder_Va01 = '/content/IBEM/Va01/images'\n",
        "\n",
        "Folder_Ts00 = '/content/IBEM/Ts00/images'\n",
        "Folder_Ts01 = '/content/IBEM/Ts01/images'\n",
        "Folder_Ts10 = '/content/IBEM/Ts10/images'\n",
        "Folder_Ts11 = '/content/IBEM/Ts11/images'\n",
        "\n",
        "AllFiles = GetFiles([Folder_Tr00, Folder_Tr01, Folder_Tr10, Folder_Va00, Folder_Va01, Folder_Ts00, Folder_Ts01, Folder_Ts10, Folder_Ts11], 'jpg')\n",
        "print(len(AllFiles))\n",
        "\n",
        "Tr00Files = GetFiles([Folder_Tr00], 'jpg')\n",
        "Ts10Files = GetFiles([Folder_Ts10], 'jpg')\n",
        "Ts11Files = GetFiles([Folder_Ts11], 'jpg')\n"
      ],
      "metadata": {
        "id": "0Fj0Ig-7WXoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "def GetLabel(yaml_file):\n",
        "    class_names = []\n",
        "    with open(yaml_file, \"r\", encoding=\"utf-8\") as stream:\n",
        "        try:\n",
        "            data_loaded = yaml.safe_load(stream)\n",
        "            #print(data_loaded['names'])\n",
        "            class_names = list(data_loaded['names'].values())\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "    return class_names\n",
        "\n",
        "\n",
        "def Txt2Regions(txt_fn, img):\n",
        "    img_h, img_w = img.shape[:2]\n",
        "    # ground truth math expressions\n",
        "    Regions = []\n",
        "    with open(txt_fn, 'r') as f:\n",
        "        for i, line in enumerate(f.readlines()):\n",
        "            line = line.strip('\\n').split(' ')\n",
        "            label = int(float(line[0]))\n",
        "\n",
        "            nPoints = (len(line)-1)//2\n",
        "            if nPoints == 2: # detection\n",
        "                x, y = float(line[1]), float(line[2])\n",
        "                w, h = float(line[3]), float(line[4])\n",
        "                l, t = x - w/2, y - h/2\n",
        "                r, b = x + w/2, y + h/2\n",
        "                l, t = int(l*img_w), int(t*img_h)\n",
        "                r, b = int(r*img_w), int(b*img_h)\n",
        "\n",
        "                Regions.append(Region(str(label), l, t, r, b))\n",
        "            else: # segmentation\n",
        "                cnt, cnt2 = [], []\n",
        "                for p in range(nPoints):\n",
        "                    x = float(line[2*p+1])\n",
        "                    y = float(line[2*p+2])\n",
        "                    cnt.append(int(x*img_w+1))\n",
        "                    cnt.append(int(y*img_h-1))\n",
        "                    cnt2.append([int(x*img_w+1), int(y*img_h-1)])\n",
        "\n",
        "                cnt = np.asarray(cnt)\n",
        "                cnt2 = np.asarray(cnt2)\n",
        "                x,y,w,h = cv2.boundingRect(cnt2)\n",
        "                Regions.append(Region(str(label), x, y, x+w, y+h, poly=cnt))\n",
        "\n",
        "    return Regions\n",
        "\n",
        "data_yaml = '/content/drive/MyDrive/Data/IBEM/IBEM.yaml'\n",
        "class_names = GetLabel(data_yaml)\n",
        "num_classes = len(class_names)\n",
        "print(class_names)\n",
        "\n",
        "def IBEMLoad(img_fn):\n",
        "    # image\n",
        "    img = cv2.imread(img_fn)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # regions\n",
        "    txt_fn = img_fn.replace('images', 'labels').replace('.jpg', '.txt')\n",
        "    RegionsGT = Txt2Regions(txt_fn, img)\n",
        "\n",
        "    # adjust regions\n",
        "    bw = Binary(img)\n",
        "    RegionsGT = AdjustGTs(RegionsGT, bw)\n",
        "\n",
        "    return img, RegionsGT\n",
        "\n",
        "# View data\n",
        "ViewData(Ts11Files[115], IBEMLoad)"
      ],
      "metadata": {
        "id": "rXkVoXyqWZPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ...and test"
      ],
      "metadata": {
        "id": "-7N0gKO9WenU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jsy-3F9VWgGM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}